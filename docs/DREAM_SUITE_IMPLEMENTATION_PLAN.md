# Dream Suite Implementation Plan
**Sequential, No Parallelization - Build it Right**

---

## Current Status

### ✅ Completed
- OAuth configured: Instagram, Facebook, Spotify, YouTube
- Onboarding page with platform connection buttons
- User authentication (Supabase)
- XP/leveling/gamification system
- Main Dream Suite dashboard page (placeholder)

### ⏸️ Deferred
- TikTok OAuth (waiting to complete setup)
- SoundCloud OAuth (API approval pending)
- Apple Music (developer enrollment pending)

---

## Phase 1: Database Foundation (DO FIRST)
**Goal:** Create the "contract" that everything else depends on

### Step 1.1: Create Supabase Tables
**File:** Create migration `supabase/migrations/YYYYMMDDHHMMSS_create_dream_suite_tables.sql`

**Tables to create:**
```sql
-- 1. Platform connections (which platforms user has connected)
CREATE TABLE platform_connections (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  platform TEXT NOT NULL, -- 'instagram', 'spotify', etc.
  platform_user_id TEXT, -- Their ID on that platform
  platform_username TEXT,
  access_token TEXT, -- Encrypted
  refresh_token TEXT, -- Encrypted
  token_expires_at TIMESTAMPTZ,
  connected_at TIMESTAMPTZ DEFAULT NOW(),
  last_synced_at TIMESTAMPTZ,
  is_active BOOLEAN DEFAULT true,
  UNIQUE(user_id, platform)
);

-- 2. Daily metrics (aggregated stats per platform per day)
CREATE TABLE daily_metrics (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  platform TEXT NOT NULL,
  date DATE NOT NULL,

  -- Common metrics (extracted from JSONB for fast queries)
  follower_count BIGINT,
  follower_change_24h INTEGER,
  engagement_total BIGINT,
  content_count INTEGER,

  -- Platform-specific data (full payload)
  metrics JSONB NOT NULL,

  collected_at TIMESTAMPTZ DEFAULT NOW(),
  created_at TIMESTAMPTZ DEFAULT NOW(),

  UNIQUE(user_id, platform, date)
);

-- 3. Content posts (individual posts/videos/tracks across platforms)
CREATE TABLE content_posts (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  platform TEXT NOT NULL,
  platform_post_id TEXT NOT NULL, -- ID on that platform

  -- Post metadata
  post_type TEXT, -- 'photo', 'video', 'reel', 'story', 'track', etc.
  caption TEXT,
  media_url TEXT,
  permalink TEXT,

  -- Performance metrics
  likes INTEGER DEFAULT 0,
  comments INTEGER DEFAULT 0,
  shares INTEGER DEFAULT 0,
  views INTEGER DEFAULT 0,
  plays INTEGER DEFAULT 0,

  -- Timestamps
  posted_at TIMESTAMPTZ,
  last_updated_at TIMESTAMPTZ DEFAULT NOW(),
  created_at TIMESTAMPTZ DEFAULT NOW(),

  UNIQUE(user_id, platform, platform_post_id)
);

-- 4. AI insights (generated by LangChain agents)
CREATE TABLE ai_insights (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,

  -- Insight metadata
  insight_type TEXT NOT NULL, -- 'growth', 'content', 'strategy', 'trend', 'goal'
  priority TEXT DEFAULT 'medium', -- 'low', 'medium', 'high', 'urgent'

  -- Insight content
  title TEXT NOT NULL,
  message TEXT NOT NULL,
  action_items JSONB, -- Suggested actions
  data_sources JSONB, -- Which platforms/metrics this is based on

  -- Status
  is_read BOOLEAN DEFAULT false,
  is_dismissed BOOLEAN DEFAULT false,

  -- Timestamps
  generated_at TIMESTAMPTZ DEFAULT NOW(),
  expires_at TIMESTAMPTZ, -- Optional expiry for time-sensitive insights
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 5. Chat history (with AI Career Agent)
CREATE TABLE chat_messages (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,

  -- Message content
  role TEXT NOT NULL, -- 'user' or 'assistant'
  content TEXT NOT NULL,

  -- Context
  conversation_id UUID, -- Group related messages
  agent_type TEXT, -- 'career_agent', 'content_strategist', etc.

  -- Metadata
  tokens_used INTEGER,
  model_used TEXT,
  processing_time_ms INTEGER,

  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Indexes for performance
CREATE INDEX idx_platform_connections_user ON platform_connections(user_id);
CREATE INDEX idx_platform_connections_platform ON platform_connections(platform);

CREATE INDEX idx_daily_metrics_user_platform ON daily_metrics(user_id, platform);
CREATE INDEX idx_daily_metrics_date ON daily_metrics(date DESC);
CREATE INDEX idx_daily_metrics_platform ON daily_metrics(platform);

CREATE INDEX idx_content_posts_user_platform ON content_posts(user_id, platform);
CREATE INDEX idx_content_posts_posted_at ON content_posts(posted_at DESC);

CREATE INDEX idx_ai_insights_user ON ai_insights(user_id);
CREATE INDEX idx_ai_insights_priority ON ai_insights(priority, is_read);
CREATE INDEX idx_ai_insights_generated_at ON ai_insights(generated_at DESC);

CREATE INDEX idx_chat_messages_user ON chat_messages(user_id);
CREATE INDEX idx_chat_messages_conversation ON chat_messages(conversation_id);
CREATE INDEX idx_chat_messages_created_at ON chat_messages(created_at DESC);
```

### Step 1.2: Set Up Row Level Security (RLS)
**Security policies to ensure users only see their own data**

```sql
-- Enable RLS
ALTER TABLE platform_connections ENABLE ROW LEVEL SECURITY;
ALTER TABLE daily_metrics ENABLE ROW LEVEL SECURITY;
ALTER TABLE content_posts ENABLE ROW LEVEL SECURITY;
ALTER TABLE ai_insights ENABLE ROW LEVEL SECURITY;
ALTER TABLE chat_messages ENABLE ROW LEVEL SECURITY;

-- Policies: Users can only access their own data
CREATE POLICY "Users can view own platform connections"
  ON platform_connections FOR SELECT
  USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own platform connections"
  ON platform_connections FOR INSERT
  WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update own platform connections"
  ON platform_connections FOR UPDATE
  USING (auth.uid() = user_id);

-- Repeat for other tables...
CREATE POLICY "Users can view own daily metrics"
  ON daily_metrics FOR SELECT
  USING (auth.uid() = user_id);

CREATE POLICY "Users can view own content posts"
  ON content_posts FOR SELECT
  USING (auth.uid() = user_id);

CREATE POLICY "Users can view own AI insights"
  ON ai_insights FOR SELECT
  USING (auth.uid() = user_id);

CREATE POLICY "Users can update own AI insights"
  ON ai_insights FOR UPDATE
  USING (auth.uid() = user_id);

CREATE POLICY "Users can view own chat messages"
  ON chat_messages FOR SELECT
  USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own chat messages"
  ON chat_messages FOR INSERT
  WITH CHECK (auth.uid() = user_id);
```

### Step 1.3: Update OAuth Callback to Save Connections
**File:** `app/api/auth/callback/[platform]/route.ts`

**After successful OAuth, save to `platform_connections` table:**
```typescript
// After exchanging code for token...
await supabase
  .from('platform_connections')
  .upsert({
    user_id: session.user.id,
    platform: platform,
    platform_user_id: userInfo.id,
    platform_username: userInfo.username,
    access_token: encrypt(tokens.access_token), // Use encryption!
    refresh_token: tokens.refresh_token ? encrypt(tokens.refresh_token) : null,
    token_expires_at: new Date(Date.now() + tokens.expires_in * 1000),
    last_synced_at: new Date(),
    is_active: true
  });
```

---

## Phase 2: Data Collection (n8n Workflows)
**Goal:** Collect real data from connected platforms daily

### Step 2.1: Set Up n8n Instance
**Options:**
- Self-hosted (Docker on Vercel/Railway)
- n8n Cloud (easier, $20/month)

**Decision needed:** Which hosting approach?

### Step 2.2: Create Workflow Template
**Structure for all platform workflows:**

1. **Trigger:** Cron (daily at 2 AM)
2. **Get Users:** Query Supabase for users with `platform_connections.platform = 'instagram'` and `is_active = true`
3. **For Each User:**
   - Get access token from `platform_connections`
   - Check if token expired → refresh if needed
   - Call platform API
   - Transform data to match schema
   - Insert into `daily_metrics` table
   - Update `last_synced_at` in `platform_connections`
4. **Error Handling:** Log failures, notify admin

### Step 2.3: Build Platform-Specific Workflows

#### Workflow 1: Instagram Data Collection
**API Endpoints:**
- `/me` - User profile
- `/me/media` - Posts
- `/me/insights` - Analytics

**Metrics to collect:**
- Follower count
- Post engagement
- Story views
- Reach & impressions

#### Workflow 2: Facebook Data Collection
**API Endpoints:**
- `/me/accounts` - Pages
- `/{page-id}/insights` - Page analytics

#### Workflow 3: Spotify Data Collection
**API Endpoints:**
- `/me` - User profile
- `/me/top/tracks` - Top tracks
- `/me/playlists` - Playlists

**Note:** Spotify Web API only has user data, not artist streaming stats (need Spotify for Artists API separately)

#### Workflow 4: YouTube Data Collection
**API Endpoints:**
- `/channels?mine=true` - Channel stats
- `/videos?part=statistics` - Video performance
- YouTube Analytics API - Watch time, demographics

---

## Phase 3: LangChain AI Agent Architecture
**Goal:** Intelligent analysis and insights from collected data

### Step 3.1: Design Agent System
**File:** Create `lib/ai/agents/`

**Agent Types:**

1. **Career Agent** (`career-agent.ts`)
   - Analyzes growth trends
   - Provides strategic advice
   - Answers questions about performance

2. **Content Strategist** (`content-strategist.ts`)
   - Recommends content types
   - Suggests posting times
   - Analyzes what content performs best

3. **Goal Tracker** (`goal-tracker.ts`)
   - Monitors progress toward goals
   - Celebrates milestones
   - Suggests achievable next steps

### Step 3.2: Set Up LangChain Infrastructure
**Install dependencies:**
```bash
npm install langchain @langchain/openai @langchain/community
```

**Create base agent:**
```typescript
// lib/ai/agents/base-agent.ts
import { ChatOpenAI } from '@langchain/openai';
import { createServiceRoleClient } from '@/utils/supabase/service-role';

export abstract class BaseAgent {
  protected llm: ChatOpenAI;
  protected supabase: ReturnType<typeof createServiceRoleClient>;

  constructor() {
    this.llm = new ChatOpenAI({
      modelName: 'gpt-4',
      temperature: 0.7,
      openAIApiKey: process.env.OPENAI_API_KEY,
    });
    this.supabase = createServiceRoleClient();
  }

  abstract analyze(userId: string): Promise<void>;
}
```

### Step 3.3: Implement Career Agent
**File:** `lib/ai/agents/career-agent.ts`

**Capabilities:**
- Query `daily_metrics` for trends
- Generate insights
- Save to `ai_insights` table
- Respond to chat queries

### Step 3.4: Build Tools for Agents
**LangChain tools to access data:**

```typescript
// lib/ai/tools/get-metrics.ts
import { DynamicStructuredTool } from '@langchain/core/tools';
import { z } from 'zod';

export const getMetricsTool = new DynamicStructuredTool({
  name: 'get_metrics',
  description: 'Get platform metrics for a user',
  schema: z.object({
    userId: z.string(),
    platform: z.string(),
    startDate: z.string(),
    endDate: z.string(),
  }),
  func: async ({ userId, platform, startDate, endDate }) => {
    // Query daily_metrics table
    const { data } = await supabase
      .from('daily_metrics')
      .select('*')
      .eq('user_id', userId)
      .eq('platform', platform)
      .gte('date', startDate)
      .lte('date', endDate)
      .order('date', { ascending: false });

    return JSON.stringify(data);
  },
});
```

---

## Phase 4: AI Chat Interface
**Goal:** Let users talk to the Career Agent

### Step 4.1: Create Chat API Route
**File:** `app/api/dream-suite/chat/route.ts`

**Functionality:**
- Accept user message
- Load conversation history
- Call LangChain agent with context
- Stream response back
- Save to `chat_messages` table

### Step 4.2: Build Chat UI Component
**File:** `components/dream-suite/CareerAgentChat.tsx`

**Features:**
- Message input
- Chat history display
- Streaming responses
- Suggested prompts
- Context awareness (knows what data user has)

### Step 4.3: Integrate into Dashboard
**File:** `app/profile/dream-suite/page.tsx`

**Layout:**
- Left sidebar: Platform connections, quick stats
- Center: Chat interface with Career Agent
- Right sidebar: AI-generated insights, goal progress

---

## Phase 5: Analytics Dashboard
**Goal:** Beautiful visualizations of platform data

### Step 5.1: Install Chart Libraries
```bash
npm install recharts date-fns
```

### Step 5.2: Create Dashboard Components
**Files:**
- `components/dream-suite/FollowerGrowthChart.tsx`
- `components/dream-suite/EngagementChart.tsx`
- `components/dream-suite/PlatformComparison.tsx`
- `components/dream-suite/TopContent.tsx`

### Step 5.3: Build Dashboard API Routes
**File:** `app/api/dream-suite/analytics/route.ts`

**Endpoints:**
- `/api/dream-suite/analytics/overview` - Summary stats
- `/api/dream-suite/analytics/growth` - Follower trends
- `/api/dream-suite/analytics/engagement` - Engagement over time
- `/api/dream-suite/analytics/content` - Top performing content

---

## Phase 6: Daily AI Insights Cron
**Goal:** Automatically generate insights every day

### Step 6.1: Create Cron Job
**File:** `app/api/cron/generate-insights/route.ts`

**Process:**
1. Get all active users
2. For each user:
   - Run Career Agent analysis
   - Generate insights
   - Save to `ai_insights` table
3. Email digest (optional)

### Step 6.2: Configure Vercel Cron
**File:** `vercel.json`
```json
{
  "crons": [{
    "path": "/api/cron/generate-insights",
    "schedule": "0 6 * * *"
  }]
}
```

---

## Phase 7: Testing & Polish
**Goal:** Make it production-ready

### Step 7.1: Test Each Platform Integration
- [ ] Instagram data collection works
- [ ] Facebook data collection works
- [ ] Spotify data collection works
- [ ] YouTube data collection works

### Step 7.2: Test AI Features
- [ ] Career Agent responds accurately
- [ ] Insights are relevant
- [ ] Chat saves properly

### Step 7.3: Error Handling
- [ ] Token refresh works
- [ ] Failed API calls retry
- [ ] Users notified of issues

### Step 7.4: Performance Optimization
- [ ] Database queries optimized
- [ ] API responses cached
- [ ] Charts load quickly

---

## Dependencies & Prerequisites

**Required Before Starting:**
- [x] Supabase project set up
- [x] OAuth configured for 4 platforms
- [ ] OpenAI API key (for LangChain)
- [ ] n8n instance (hosted or cloud)
- [ ] Vercel deployment

**Environment Variables Needed:**
```bash
# Existing
NEXT_PUBLIC_SUPABASE_URL=...
NEXT_PUBLIC_SUPABASE_ANON_KEY=...
SUPABASE_SERVICE_ROLE_KEY=...

# New for Dream Suite
OPENAI_API_KEY=sk-...
N8N_WEBHOOK_URL=https://...
ENCRYPTION_KEY=... # For encrypting tokens
```

---

## Timeline Estimate (Working Sequentially)

- **Phase 1:** Database Foundation - 2 hours
- **Phase 2:** n8n Workflows - 4 hours (1 hour per platform)
- **Phase 3:** LangChain Agents - 6 hours
- **Phase 4:** Chat Interface - 3 hours
- **Phase 5:** Analytics Dashboard - 4 hours
- **Phase 6:** Daily Insights Cron - 2 hours
- **Phase 7:** Testing & Polish - 3 hours

**Total:** ~24 hours of focused development

---

## Decision Points (Need Your Input)

1. **n8n Hosting:** Self-hosted or n8n Cloud ($20/month)?
2. **OpenAI Budget:** How much can we spend on API calls?
3. **Insight Frequency:** Daily insights or real-time?
4. **Chart Library:** Recharts (simple) or D3 (advanced)?
5. **Error Notifications:** Email admins or just log?

---

## Next Immediate Action

**START HERE:**
1. Create Supabase migration file
2. Run migration
3. Update OAuth callback to save connections

Ready to begin Phase 1?
